---
title: 'Übungen: Lineare Regression'
author: "Lukas Stammler"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_height: 6
    fig_width: 6
    fig_align: "center"
    highlight: pygments
    theme: yeti
    code_download: false
---

```{r setup, include=FALSE}
rm(list = ls())

knitr::opts_chunk$set(echo = FALSE, message = FALSE)

library(tidyverse)
library(jmv)
library(knitr)
library(scatr)
library(equatiomatic)
```

# Technische Vorbemerkung

* Die Übungen sind für die Arbeit mit [jamovi](https://www.jamovi.org/) [1] angelegt, können aber mit jeder anderen Statistiksoftware bearbeitet werden.    
* Die Datensätze für alle Übungen können  [hier](https://github.com/lukasstammler/statexercises/blob/main/data/data_statexercises.zip) als zip-Datei heruntergeladen werden. Es wird empfohlen, alle Datensätze im gleichen Ordner abzulegen.   
* Die Datensätze liegen im `.csv`-Format vor (header = TRUE, sep = ",", dec = ".") und können direkt in jamovi geöffnet werden. Es wird empfohlen, nach der Kategorisierung der Variablen in jamovi, die Datei im jamovi-Format `.omv` zu speichern.   
    
[1] The jamovi project (2021). jamovi (Version 1.6) [Computer Software]. Retrieved from https://www.jamovi.org   

<br/>


# Einführung

Im Prinzip sind die Modelle der linearen Regression eine ausgefeiltere Version der Korrelation nach Pearson, allerdings können sie viel mehr. 

Wie wir bei den Übungen zur Korrelation gelernt haben, misst der Korrelationskoeffizient das Mass, in dem sich die Daten auf einer perfekten Linie befinden. Aus der Schule wissen wir (ist lange her), dass eine Gerade mathematisch beschrieben wird mit der Formel:

$$y = \beta_0 + \beta_1 \times x$$

Wobei:   

* $\beta_0$ = Schnittpunkt der Geraden mit der y-Achse wenn x = 0      
* $\beta_1$ = Steigung der Geraden ($\Delta y/\Delta x$ d.h. um welchen Betrag nimmt y zu oder ab, wenn x um eine Einheit verändert wird)    
* $y$ = abhängige Variable    
* $x$ = unabhängige Variable = Prädiktorvariable

Die Gerade, welche insgesamt den geringsten Abstand zu allen Datenpunkten hat, nennt man *Regressionsgerade*. 

Wie aus der Formel ersichtlich, ist im Regressionsmodell die y-Variable abhängig von der x-Variablen, d.h. wir gehen hier von einem ursächlichen Zusammenhang zwischen den beiden Variablen aus: Die Ausprägung von x bestimmt die Ausprägung von y, mit anderen Worten, der Zusammenhang ist so, dass der Wert von x den Wert von y voraussagt. Daher wird x auch als Prädiktorvariable bezeichnet.   

**Beispiel:**

* Wir wissen, dass grösser gewachsene Menschen üblicherweise eine grössere Schuhgrösse tragen. Es scheint also ein Zusammenhang zwischen Körpergrösse und Schuhgrösse zu bestehen und wir können das einfach mit einer Korrelation prüfen. In der Regressionsanalyse stellt sich allerdings zusätzlich die Frage, wie der Zusammenhang ist. Nun wird kaum jemand auf die Idee kommen, dass die Körpergrösse eine Funktion der Schuhgrösse ist und wir dürfen davon ausgehen, dass es genau umgekehrt ist, d.h.dass die Schuhgrösse von der Körpergrösse abhängt. Damit wird die Schuhgrösse zur abhängigen Variable y und die Körpergrösse zur unabhängigen Variable x.

$$Schuhgrösse = \beta_0 + \beta_1 \times Körpergrösse$$

```{r, fig.align='center'}
phy <- read_csv("../data/physio.csv")

ggplot(phy, aes(x = Groesse, y = Schuhgroesse)) +
  geom_point(size = 3, color = "red", alpha = .5) +
  geom_smooth(method = "lm") +
  ggtitle("Schuhgrösse ~ Körpergrösse bei Physiotherapeut*innen, n = 228") +
  theme_classic()
```


* Die Grafik zeigt einen linearen Zusammenhang zwischen Schuhgrösse und Körpergrösse. Die blaue Linie ist die Regressionsgrade. Sie wird vom PC so berechnet, dass die Summe der quadrierten Abstände aller Punkte minimal ist. Die Steigung der Geraden $\beta_1$ gibt uns an, um wieviel die Schuhgrösse zunimmt, wenn die Körpergrösse um eine Einheit zunimmt. So genau lässt sich das aber nicht ablesen und deshalb lassen wir den PC unser Regressionsmodell rechnen.    

```{r}
jmv::linReg(
  data = phy,
  dep = Schuhgroesse,
  covs = Groesse,
  blocks = list(
    list("Groesse")),
  refLevels = list()
)
 
```

* Jetzt können wir die Koeffizienten $\beta_0$ (= Estimate Intercept) und $\beta_1$ (= Estimate Groesse) in unsere Formel einsetzen:    

```{r}
model <- lm(Schuhgroesse ~ Groesse, phy)
extract_eq(model, use_coefs = TRUE)
```
   
   
* Setzen wir für x = 170 ein, erhalten wir eine Schätzung für die $Schuhgrösse = -6.41 + 0.27 \times 170 = 39.49$, d.h. wir erwarten bei 170 cm grossen Menschen eine Schuhgrösse zwischen 39 und 40.   

* Setzen wir für x = 0 ein, ist die Schuhgrösse -6.41, was natürlich Unsinn ist, da erstens keine Menschen mit der Körpergrösse 0 cm existieren und zweitens eine negative Schuhgrösse keinen Sinn macht. Generell werden wir uns mit der Interpretation des Koeffizienten $\beta_0$ in diesem Kurs zurückhalten.   
* Frauen haben bei gleicher Körpergrösse kleinere Füsse als Männer. Wir werden im Verlaufe der Übungen sehen, dass wir unsere Vorhersage der Schuhgrösse verbessern können, wenn wir das Geschlecht in unserem Modell berücksichtigen.  

* $R^2$ ist ein Qualitätsmerkmal für die Güte des Regressionsmodells und wird als *Bestimmtheitsmass* bezeichnet. Die Interpretation ist relativ einfach: Der Wert von $R^2$ gibt an, zu welchem Anteil (Prozentsatz) sich die Varianz der abhängigen Variable $y$ durch die unabhängige Variable $x$ erklären lässt. Im einfachen linearen Regressionsmodell gilt $R^2$ = $r^2$, wobei $r$ der Korrelationskoeffizient nach Pearson ist (im jamovi-Output als $R$ angegeben).    

# Übung 1 {.tabset}

## Aufgabe

Wir haben eine Regression, die das Körpergewicht (kg) von der Körpergrösse (cm) vorhersagt. Welche Einheiten haben Korrelationskoeffizient $r$, Achsenabschnitt $\beta_0$ und Steigung $\beta_1$?  

<br/>

## Lösung

- Der Korrelationskoeffizient ist dimensionslos (keine Einheit)  
- Achsenabschnitt $\beta_0$: kg   
- Steigung $\beta_1$: kg/cm   

<br/>

# Übung 2 {.tabset}

## Aufgabe  

In welchem Fall a) oder b) ist die Unsicherheit für den Schätzer von $\beta_1$ grösser? Begründen Sie ihre Antwort.      

a) Wenn die Punkte stark um die Regressionsgerade streuen   
b) Wenn die Punkte wenig um die Regressionsgerade streuen   

<br/>

## Lösung   

Im Fall von a) ist die Unsicherheit grösser. Je mehr die Punkte um die Regressionsgerade streuen, desto kleiner ist der Korrelationskoeffizient und damit die Unsicherheit für den Schätzer von $\beta_1$.   

<br/>

# Übung 3 {.tabset}  

## Aufgabe  

Wir erstellen ein Regressionsmodell um die Inzidenz von Hautkrebs (pro 1000 Menschen) von der Anzahl Sonnentage in einem Jahr vorherzusagen. Für das Jahr 2019 sagt unser Modell eine Inzidenz von 1.5 Hautkrebserkrankungen pro 1000 Menschen voraus. Das Residuum für dieses Jahr beträgt 0.5. Hat unser Modell die Inzidenz unter- oder überschätzt? Begründen Sie ihre Antwort.   

<br/>

## Lösung   

Unser Modell hat die Inzidenz unterschätzt. Ein Residuum wird berechnet als $\epsilon = beobachteter ~ Wert - gefitteter ~ Wert$. Ein positives Residuum bedeutet daher, dass der vorhergesagte (gefittete) Wert geringer ist, als der beobachtete Wert. Effektiv betrug 2019 die Inzidenz 2 Hautkrebserkrankungen pro 1000 Menschen.  

<br/>

# Übung 4 {.tabset}

Eine Forschungsgruppe sammelte Messungen zu Körperumfang und Knochendurchmesser. Zusätzlich wurden Alter, Körpergewicht, Körpergrösse und Geschlecht erfasst. Eingeschlossen wurden 507 jugendliche und erwachsene, körperlich aktive Menschen. Wir untersuchen den Zusammenhang zwischen Schulterumfang und Körpergrösse.   

**Hinweis**   

Formel für die Berechnung der Steigung: $\beta_1 = \frac{s_y}{s_x} r$   
Formel für die Berechnung des Achsenabschnitts: $\beta_0 = \bar{y} - \beta_1 \bar{x}$

**Diese Formeln müssen nicht gelernt werden!**  

## Aufgabe

Der durchschnittliche Schulterumfang im Datensatz beträgt 107.2 cm (s = 10.37 cm). Die durchschnittliche Körpergrösse beträgt 171.14 cm (s = 9.41 cm). Der Pearson-Korrelationskoeffizient beträgt $r = 0.67$.  

1. Notieren Sie die Gleichung für die Regressionsgerade um die Grösse vorherzusagen.  
2. Interpretieren Sie die Steigung und den Achsenabschnitt in diesem Kontext.  
3. Berechnen Sie $R^2$ für die Regressionsgerade, die die Körpergrösse in Abhängigkeit vom Schulterumfang vorhersagt.   
4. Ein zufällig ausgewählter Student hat einen Schulterumfang von 100 cm. Wie gross ist der Student gemäss Ihrem Modell?  
5. Der Student aus Frage 4. ist 160 cm gross. Berechnen Sie das Residuum und erläutern Sie ihr Ergebnis.   
6. Ein einjähriges Kind hat einen Schulterumfang von 56 cm. Könnte mit unserem Modell auch dessen Körpergrösse geschätzt werden?   

<br/>

## Lösung   

1. Notieren Sie die Gleichung für die Regressionsgerade um die Grösse vorherzusagen.  

- Zuerst berechnen wir die Steigung:  

$$\beta_1 = \frac{s_y}{s_x} r = \frac{9.41}{10.37}\times0.67 = 0.608$$  
- jetzt berechnen wir den Achsenabschnitt: 

$$\beta_0 = \bar{y} - \beta_1 \bar{x} = 171.14 - 0.608 \times 107.2 = 105.96$$

- Jetzt können wir die Regressionsgleichung aufstellen:  

$$\widehat{Groesse} = 105.96 + 0.608 \times Schulterumfang$$

2. Interpretieren Sie die Steigung und den Achsenabschnitt in diesem Kontext.  

- Steigung: Für jeden cm Zunahme des Schulterumfangs, erwarten wir eine durchschnittliche Grössenzunahme von 0.608 cm.   
- Achsenabschnitt: Für Menschen mit einem Schulterumfang von 0 cm erwarten wir eine durchschnittliche Körpergrösse von 105.96 cm. Diese Aussage macht definitiv keinen Sinn.   

3. Berechnen Sie $R^2$ für die Regressionsgerade, die die Körpergrösse in Abhängigkeit vom Schulterumfang vorhersagt und erläutern Sie ihr Resultat.  

- Bei einer einfachen linearen Regression ist $R^2 = r^2 = 0.67^2 = 0.45$.
- Etwa 45% der Variation der Körpergrösse lässt sich durch unser Modell erklären, d.h. wird durch den Schulterumfang erklärt.    

4. Ein zufällig ausgewählter Student hat einen Schulterumfang von 100 cm. Wie gross ist der Student gemäss Ihrem Modell?  

- Durch einsetzen von 100 in die Gleichung ergibt sich

$$\widehat{Groesse} = 105.96 + 0.608 \times 100 \approx 167 cm$$

5. Der Student aus Frage 4. ist 160 cm gross. Berechnen Sie das Residuum und erläutern Sie ihr Ergebnis.   

$$\epsilon_i = y_i - \hat{y_i} = 160 - 167 = -7 cm$$

- Ein negatives Residuum bedeutet, dass das Modell die Grösse des Studenten überschätzt.   

6. Ein einjähriges Kind hat einen Schulterumfang von 56 cm. Könnte mit unserem Modell auch dessen Körpergrösse geschätzt werden?   

- Nein. Die Datenerhebung erfolgte bei Jugendlichen und Erwachsenen (mit Schulterumfängen von 90 bis 130 cm). Das Regressionsmodell ist nur innerhalb der gemessenen Bereiche gültig und kann nicht auf Kleinkinder extrapoliert werden.

<br/>

# Übung 5 {.tabset}

Wir untersuchen den Zusammenhang zwischen dem Herzgewicht (Hwt in g) von Katzen in Abhängigkeit von ihrem Körpergewicht (Bwt in kg). Die Regressionskoeffizienten in diesem jamovi-Output wurden anhand eines Datensatzes berechnet, der die Daten von 144 Hauskatzen umfasst.

```{r}
# library(MASS)
# data(cats)

cats <- read_csv("../data/cats.csv")

# str(cats)
scatr::scat(
  data = cats,
  x = "Bwt",
  y = "Hwt"
)

jmv::linReg(
  data = cats,
  dep = "Hwt",
  covs = "Bwt",
  blocks = list(
    list(
      "Bwt")),
  refLevels = list()
)
```

## Aufgabe

1. Notieren Sie das lineare Modell.   
2. Interpretieren Sie den Achsenabschnitt.   
3. Interpretieren Sie die Steigung.   
4. Interpretieren Sie $R^2$.  
5. Interpretieren sie $R$.    

## Lösung  

1. Notieren Sie das lineare Modell.  

$$\widehat{Hwt} = -0.357 + 4.034 \times Bwt$$

2. Interpretieren Sie den Achsenabschnitt.   

- Für eine Katze mit 0 kg Körpergewicht, erwarten wir ein Herzgewicht von -0.357 g. Diese Angabe ist offensichtlich ohne Bedeutung.   

3. Interpretieren Sie die Steigung.   

- Bei einer Zunahme des Körpergewichts einer Katze um 1 kg, erwarten wir ein Zunahme des Herzgewichts um durchschnittlich 4.034 g.   

4. Interpretieren Sie $R^2$.  

- Das Körpergewicht erklärt 64.66% der Variabilität des Herzgewichts.  

5. Interpretieren sie $R$.    

- $R$ ist der Korrelationskoeffizient nach Pearson. Mit $r = 0.80$ besteht ein starker Zusammenhang zwischen dem Körpergewicht und dem Herzgewicht von Katzen.   

<br/>

# Übung 6 {.tabset}  

Kann die Anzahl an Mordfällen pro Million Einwohner und pro Jahr (annual_murders_per_mil) aus dem prozentualen Anteil an Menschen, die in Armut leben (perc_pov) vorhergesagt werden? Die Regressionskoeffizienten in diesem jamovi-Output wurden anhand einer Zufallsstichprobe von 20 Metropolitanregionen in den USA berechnet.

```{r}
murders <- read_csv("../data/murders.csv")

scatr::scat(
  data = murders,
  x = "perc_pov",
  y = "annual_murders_per_mil"
)

jmv::linReg(
  data = murders,
  dep = "annual_murders_per_mil",
  covs = "perc_pov",
  blocks = list(
    list(
      "perc_pov")),
  refLevels = list()
)
```

<br/>

## Aufgabe  

1. Notieren Sie das lineare Modell.   
2. Interpretieren Sie den Achsenabschnitt.   
3. Interpretieren Sie die Steigung.   
4. Interpretieren Sie $R^2$.  
5. Interpretieren sie $R$.    

<br/>

## Lösung   

1. Notieren Sie das lineare Modell.   

$$\widehat{Morde} = -29.901 + 2.559 \times Armut$$

2. Interpretieren Sie den Achsenabschnitt.  

- Die erwartete Anzahl Morde in Metropolitanregionen der USA ohne Armut beträgt im Durchschnitt -29.901 pro Million Einwohner.   

3. Interpretieren Sie die Steigung.   

- Für jedes zusätzliche Prozent von Menschen, die in Armut leben, erwarten wir eine Zunahme um durchschnittlich 2.559 Morde pro Million Einwohner in Metropolitanregionen der USA.  

4. Interpretieren Sie $R^2$.  

- Der prozentuale Anteil an Menschen, die in Armut leben, erklärt 70.52% der Variabilität der Mordraten in Metropolitanregionen der USA.    

5. Interpretieren sie $R$.   

- Mit $r = 0.84$ besteht ein starker Zusammenhang zwischen dem Anteil Menschen, die in Armut leben und der Mordrate in Metropolitanregionen der USA.   

<br/>

# Übung 7 {.tabset}  

Erfahrungsgemäss hat die Schlafdauer junger Mütter einen erheblichen Einfluss auf ihre Laune. Danielle hat in einem Selbstversuch während 100 Tagen ihre Laune anhand einer selbst erstellten Skala von 0 - 100 gemessen. Zudem hat sie ihre eigene Schlafdauer und diejenige ihres Babys gemessen.  

Wir arbeiten mit dem Datesatz `parenthood.csv`. Der Datensatz stammt aus dem Lehrbuch *Learning Statistics with jamovi* von Danielle Navarro und David Foxcroft und enthält 5 Variablen

| Variable | Erläuterung |
|:-|:-|
| ID | Eine ID für jede Messung, 1...100 |
| dan.sleep | Dan's (Danielle's) Schlafdauer in Stunden |
| baby.sleep | Die Schlafdauer von Dan's Baby in Stunden |
| dan.grump | Dan's Schlechte-Laune-Score, Skala von 0 (super gute Laune) bis 100 (maximal schlecht gelaunt) |
| day | wie ID (überflüssige Variable) |

<br/>

## Aufgabe

```{r}
parenthood <- read_csv("../data/parenthood.csv")
```

Besteht ein Zusammenhang zwischen der Stimmung von Dan (Danielle) und ihrer Schlafdauer?  

0. Laden Sie den Datensatz in jamovi    
1. Formulieren Sie Ihre Hypothesen.    
2. Erstellen Sie eine Tabelle mit den deskriptiven Kennzahlen.    
3. Überlegen Sie welches die abhängige und die unabhängige Variable ist und erstellen Sie ein Punktediagramm mit einer Regressionsgeraden.
4. Berechnen Sie den passenden Korrelationskoeffizienten.       
5. Erstellen Sie ein einfaches lineares Regressionsmodell und notieren Sie die Gleichung.    
6. Formulieren Sie Ihre Resultate.    

<br />

## Lösung

1. Formulieren Sie Ihre Hypothesen.  

* $H_0$: Es besteht kein Zusammenhang zwischen Dan's Stimmung und ihrer Schlafdauer.    
* $H_A$: Es besteht ein Zusammenhang zwischen Dan's Stimmung und ihrer Schlafdauer.   

<br />

2. Erstellen Sie eine Tabelle mit den deskriptiven Kennzahlen.    

```{r}
jmv::descriptives(
  data = parenthood,
  vars = vars(dan.sleep, dan.grump),
  sd = TRUE
)
```
<br />

3. Überlegen Sie welches die abhängige und die unabhängige Variable ist und erstellen Sie ein Punktediagramm mit einer linearen Regressionsgeraden.

```{r}
scatr::scat(
  data = parenthood,
  x = "dan.sleep",
  y = "dan.grump",
  line = "linear"
)
```

- Es besteht ein negativer linearer Zusammenhang zwischen der Schlafdauer von Dan und ihrer Laune. Je länger Dan schläft, desto tiefer ist ihr Schlechte-Laune-Score.

<br />

4. Berechnen Sie den passenden Korrelationskoeffizienten.    

```{r}
jmv::corrMatrix(
  data = parenthood, 
  vars = vars(dan.sleep, dan.grump),
  ci = TRUE
)
```

- Der Korrelationskoeffizient $r = -0.90$. Damit besteht ein starker Zusammenhang zwischen Dan's Schlafdauer und ihrer Laune.  

<br />

5. Erstellen Sie ein einfaches lineares Regressionsmodell.    

```{r}
jmv::linReg(
  data = parenthood, 
  dep = dan.grump,
  covs = dan.sleep,
  blocks = list(
    list("dan.sleep")
  ),
  refLevels = list(),
  ci = TRUE
)
```
<br />

```{r}
m000 <- lm(dan.grump ~ dan.sleep, data = parenthood)
extract_eq(m000, use_coefs = TRUE)
```
<br />

6. Formulieren Sie Ihre Resultate.    

**Zwischen Dan's Schlafdauer und ihrer Laune besteht ein negativer linearer Zusammenhang, d.h. je kürzer ihre Schlafdauer, desto höher ihr Schlechte-Laune-Score. Der Zusammenhang ist stark und signifikant, $r_p$ = .9033[-0.9341, -0.8595], p < .0001.** (Nebenbemerkung: Dan scheint eher ein Grummel zu sein, hat sie doch im Durchschnitt über die 100 Tage 63.7 Punkte auf ihrer Skala und mit einem Minimum von 41 Punkten nie wirklich gute Laune)    

**Eine einfache lineare Regression mit Schlechte-Laune-Score als abhängiger Variable und Schlafdauer als unabhängiger Variable wurde durchgeführt. Der geschätzte Regressionskoeffizient $\beta_1$ für Schlaf beträgt -8.94 [-9.79, -8.09], p < .0001). Dan's Laune verbessert sich somit im Durchschnitt um -8.94 [-9.79, -8.09] Punkte pro Stunde, die sie mehr Schlaf bekommt. Die Schlafdauer erklärt 81.6% der Variabilität von Dan's Laune ($R^2$ = .8161) **

<br />

# Übung 8 {.tabset}

## Aufgabe

Wir arbeiten mit dem gleichen Datensatz wie in Übung 1.

Die Frage lautet: Besteht ein Zusammenhang zwischen der Schlaufdauer von Dan und von ihrem Baby?  

0. Laden Sie den Datensatz in jamovi (ist vermutlich schon geschehen)    
1. Formulieren Sie Ihre Hypothesen.    
2. Erstellen Sie eine Tabelle mit den deskriptiven Kennzahlen.    
3. Überlegen Sie welches die abhängige und die unabhängige Variable ist und erstellen Sie ein Punktediagramm mit einer Regressionsgeraden.
4. Berechnen Sie den passenden Korrelationskoeffizienten.       
5. Erstellen Sie ein einfaches lineares Regressionsmodell und notieren Sie die Regressionsgleichung.    
6. Formulieren Sie Ihre Resultate.    

<br />

## Lösung

1. Formulieren Sie Ihre Hypothesen.  

* $H_0$: Es besteht kein Zusammenhang zwischen der Schlafdauer von Dan und ihrem Baby.    
* $H_A$: Es besteht ein Zusammenhang zwischen der Schlafdauer von Dan und ihrem Baby.
<br />

2. Erstellen Sie eine Tabelle mit den deskriptiven Kennzahlen.    

```{r}
#parenthood <- read_csv("../data/parenthood.csv")

jmv::descriptives(
  data = parenthood,
  vars = vars(baby.sleep, dan.sleep),
  sd = TRUE
)
```

<br />

3. Überlegen Sie welches die abhängige und die unabhängige Variable ist und erstellen Sie ein Punktediagramm mit einer Regressionsgeraden.

```{r}
scatr::scat(
  data = parenthood,
  x = "baby.sleep",
  y = "dan.sleep",
  line = "linear"
)
```

- Es besteht ein positiver linearer Zusammenhang zwischen der Schlafdauer des Babys und Dan's Schlafdauer.   

<br />

4. Berechnen Sie den passenden Korrelationskoeffizienten.    

```{r}
jmv::corrMatrix(
  data = parenthood, 
  vars = vars(baby.sleep, dan.sleep),
  ci = TRUE
)
```

- Mit $r = 0.63$ besteht ein mittlerer Zusammenhang zwischen der Schlafdauer des Babys und Dan's Schlafdauer.

<br />

5. Erstellen Sie ein einfaches lineares Regressionsmodell.    

```{r}
jmv::linReg(
  data = parenthood, 
  dep = dan.sleep,
  covs = baby.sleep,
  blocks = list(
    list("baby.sleep")
  ),
  refLevels = list(),
  ci = TRUE
)
```

<br />

```{r}
m001 <- lm(dan.sleep ~ baby.sleep, data = parenthood)
extract_eq(m001, use_coefs = TRUE)
```

<br />


6. Formulieren Sie Ihre Resultate.    

**Zwischen der Schlafdauer von Dan's Baby und ihrer eigenen Schlafdauer besteht ein positive linearer Zusammenhang, d.h. je länger das Baby schläft, desto länger schläft auch Dan. Der Zusammenhang ist mässig und signifikant, $r_p$ = 0.6279 [0.4922, 0.7339], p < 0.0001.** 

**Eine einfache lineare Regression mit Dan's Schlafdauer als abhängiger Variable und der Schlafdauer des Babys als unabhängiger Variable wurde durchgeführt. Der geschätzte Regressionskoeffizient $\beta$ für Schlaf Baby beträgt 0.3075 [0.2311, 0.3840], p < 0.0001). Pro Stunde Schlaf des Babys erhöht sich Dan's Schlafdauer demnach im Durchschnitt um 0.3075 [.2311, .3840] Stunden. Die Schlafdauer des Babys erklärt 39.4% der Varianz von Dan's Schlafdauer ($R^2$ = .3943)**   

<br />
<br />




